{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d3ae64-acb0-4f6b-8bad-1dd571e05b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn librosa scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31372b5-8c86-47fa-80c9-1585f328912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4872a747-a7e0-4c8f-970a-13b70e3add9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca43ad3-0a70-4507-82a7-b757f8228e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're already inside /dataset, no folder name is needed\n",
    "TRAIN_AUDIO_FOLDER = \"audios_train\"\n",
    "TEST_AUDIO_FOLDER = \"audios_test\"\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e9899-afcb-4cd3-8fcf-2be90b15c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Show current working directory\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e583aada-6373-414a-bf13-1fe944fdb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set full path to dataset folder\n",
    "DATA_FOLDER = \"D:\\\\SHL\\\\shl-intern-hiring-assessment\\\\dataset\"\n",
    "\n",
    "# List all files in the folder\n",
    "for root, dirs, files in os.walk(DATA_FOLDER):\n",
    "    print(f\"\\nDirectory: {root}\")\n",
    "    for file in files:\n",
    "        print(f\" - {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9822de-c2eb-49a6-9023-0e064bd446bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27281c-db28-47fd-b17c-8d478aa078eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_mfcc(file_path, n_mfcc=20):\n",
    "    y, sr = librosa.load(file_path, sr=None)  # load with original sampling rate\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfcc_mean = np.mean(mfcc.T, axis=0)  # average over time\n",
    "    return mfcc_mean\n",
    "\n",
    "# Prepare features\n",
    "def build_features(df, audio_dir):\n",
    "    features = []\n",
    "    valid_filenames = []\n",
    "    \n",
    "    for fname in tqdm(df['filename'], desc=\"Extracting MFCC\"):\n",
    "        path = os.path.join(audio_dir, fname)\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                mfcc = extract_mfcc(path)\n",
    "                features.append(mfcc)\n",
    "                valid_filenames.append(fname)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {fname}: {e}\")\n",
    "        else:\n",
    "            print(f\"File not found: {fname}\")\n",
    "    \n",
    "    return np.array(features), valid_filenames\n",
    "\n",
    "# Set audio folder path\n",
    "AUDIO_FOLDER = 'audios_train'  # update if needed\n",
    "\n",
    "# Extract features\n",
    "X_train, train_valid_files = build_features(train_df, AUDIO_FOLDER)\n",
    "X_test, test_valid_files = build_features(test_df, AUDIO_FOLDER)\n",
    "\n",
    "# Adjust y_train to match the valid files\n",
    "y_train = train_df[train_df['filename'].isin(train_valid_files)]['label'].values\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83bc9b-2963-4fdd-96a8-ab156f9e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_audio_dir = \"audios_test\"\n",
    "print(os.listdir(test_audio_dir))  # Should now list the .wav files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6885-1712-4bb1-ad89-366128f892ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "def extract_features(filenames, audio_dir, n_mfcc=13):\n",
    "    features = []\n",
    "    for fname in filenames:\n",
    "        file_path = os.path.join(audio_dir, fname)\n",
    "        try:\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            \n",
    "            # MFCCs\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "            \n",
    "            # Additional features\n",
    "            zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "            spec_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "            spec_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
    "            rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "\n",
    "            # Combine all features\n",
    "            feature_vector = np.concatenate([mfcc_mean, [zcr, spec_centroid, spec_bandwidth, rolloff]])\n",
    "            features.append(feature_vector)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            fallback = np.zeros(n_mfcc + 4)  # Add 4 for the extra features\n",
    "            features.append(fallback)\n",
    "    \n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebcc78-3500-4ff7-b604-dc0817e8b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = extract_features(test_df[\"filename\"], test_audio_dir)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e48003-e986-4666-8369-06c7f2df206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:10])\n",
    "print(y_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4814ec-3cb3-43e7-88b6-2c9db4f7e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'grammar_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d77f8-2027-4ddb-a0ab-8a117a4e547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = extract_features(test_df[\"filename\"], test_audio_dir, n_mfcc=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace5cd8-b0f7-4235-a78c-70686e52c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_dir = \"audios_train\"  # or whatever your folder name is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a704d-28a0-4294-b25b-f963b88dd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = extract_features(train_df[\"filename\"], train_audio_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e4bd1-a735-4a44-a679-6fc7a9930b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filenames, audio_dir, n_mfcc=13):\n",
    "    features = []\n",
    "    for fname in filenames:\n",
    "        file_path = os.path.join(audio_dir, fname)\n",
    "        try:\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "            mfcc_mean = np.mean(mfcc, axis=1)\n",
    "\n",
    "            # Add more features\n",
    "            zcr = np.mean(librosa.feature.zero_crossing_rate(y))\n",
    "            spec_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
    "            spec_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr))\n",
    "\n",
    "            features_vector = np.concatenate([mfcc_mean, [zcr, spec_centroid, spec_rolloff, chroma]])\n",
    "            features.append(features_vector)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            features.append(np.zeros(n_mfcc + 4))  # match feature length\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975d17c-0f5b-4edb-968d-851c9924ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = extract_features(train_df[\"filename\"], train_audio_dir)\n",
    "X_test = extract_features(test_df[\"filename\"], test_audio_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99e0b43-337a-4d10-b480-9fcc61b8f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926bea67-b46e-42c0-ba95-a89feff76a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.dtype)\n",
    "print(y_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65522ef0-636c-406c-b582-00ec493b5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the training data\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model on training split\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "# Predict on validation split\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate RMSE and R²\n",
    "rmse = mean_squared_error(y_val, y_val_pred) ** 0.5\n",
    "\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Manual Validation RMSE: {rmse:.4f}\")\n",
    "print(f\"Manual Validation R²: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6834e-9110-485c-b48c-a61f8129d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.clip(y_pred, 1.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a348e-659d-46ef-95cd-6986bde2ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame({\n",
    "    'filename': test_df['filename'],  # assuming you have this column\n",
    "    'label': np.clip(y_pred, 1.0, 5.0)  # clip to range [1, 5]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc775fa-463d-4fcf-84e5-5184535a518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926a7a56-78dc-45a3-a884-36338dd5dcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"grammar_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c56c40-a944-481f-91f5-51c616442428",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f10bf8-094f-49c3-a849-c7952e4e620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.05)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388a557-5b3b-4953-a616-08b1318b1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad15044-b85d-41ac-ac42-f4258d11055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50492d3-7363-46ff-93c5-5a4b7ea1f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_df[\"filename\"],  # or your unique identifier\n",
    "    \"Label\": test_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3df4b7d-41be-429b-9fa6-700f1e38a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24e344-14b3-426e-bc18-0d03beb30aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe23319-0c04-4683-a24b-865ed95e9428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dced0e-de77-4e6e-b212-ce8c7bd337c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433146df-6799-40d3-a4a9-f2eee1a84eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_df[\"filename\"],  # Adjust column name if different\n",
    "    \"Label\": test_predictions\n",
    "})\n",
    "submission.to_csv(\"ridge_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbc5d5-2e53-40cb-8ba8-ac738707f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "qt = QuantileTransformer(output_distribution='normal')\n",
    "\n",
    "y_train_transformed = qt.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "model.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Inverse transform predictions\n",
    "y_pred = qt.inverse_transform(model.predict(X_test).reshape(-1, 1)).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a4991-faaa-4be1-b9c0-a6a6ee533405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "val_pred_transformed = model.predict(X_val)\n",
    "val_pred = qt.inverse_transform(val_pred_transformed.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_val, val_pred)\n",
    "r2 = r2_score(y_val, val_pred)\n",
    "\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "print(f\"Validation R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402fc1b-45d3-4668-91d4-a65b9155710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_df[\"filename\"],  # Adjust column name if needed\n",
    "    \"Label\": y_pred\n",
    "})\n",
    "submission.to_csv(\"ridge_qt_submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1c87ce-5afd-4ec8-83e1-1e7c091d6099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_val, val_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Actual vs Predicted on Validation Set\")\n",
    "plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], color='red', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbd9c5-e13e-494a-a95c-715d6b032464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6080bdc-3d37-4a37-a747-234cdbb76a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(globals().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b4376-8fc4-489e-93de-5adb77850df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005657a-0682-47ed-9e80-7129d061e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['label'] = y_pred  # or the correct column name\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229778f-7f6b-492d-b6ec-60bb4d5c8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(y_pred, label='Predictions')\n",
    "plt.title(\"RandomForest Predictions\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08715b-0982-4362-aa8f-97340fc58488",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f'Feature {i}' for i in range(X_train.shape[1])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271574ee-a098-4072-8d5d-3a55af4233b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of test_valid_files:\", len(test_valid_files))\n",
    "print(\"Length of final_predictions:\", len(final_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60826c-0a29-4753-8dd1-9d6b9c6faac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, test_valid_files = build_features(test_df, TEST_AUDIO_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c702bd7-5eaf-4fea-8757-ab015316601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267ffd7-ee6e-4120-a582-051eca85284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9b9a7-cd2a-45f4-9c7a-8c0de91f5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, train_valid_files = build_features(train_df, TRAIN_AUDIO_FOLDER)\n",
    "y_train = train_df[\"label\"].values  # or the correct column if different\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab51d26-9384-425c-8da8-e7418009b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c74c131-4000-4843-8f8f-9a91be282834",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, test_valid_files = build_features(test_df, TEST_AUDIO_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac43963-d514-4b95-b5b7-42d3d1a6b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057cddaf-6859-4b0d-9b6e-7531542761c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1d10e-69c4-4782-894f-e71522e3130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(200, 1000),\n",
    "    'max_depth': [None] + list(range(10, 50)),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist,\n",
    "    n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_rf = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07946a-c223-4ccb-a9d1-e90d9bd1158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad432b86-6eef-47de-ac17-684ec79bfb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# More trees, lower learning rate\n",
    "model = RandomForestRegressor(n_estimators=500, max_depth=None, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": y_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828b3e7-6c10-436f-85f8-90e7fec49e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit a basic model to get feature importances\n",
    "rf_temp = RandomForestRegressor(random_state=42)\n",
    "rf_temp.fit(X_train, y_train)\n",
    "\n",
    "# Get top K important features\n",
    "importances = rf_temp.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "\n",
    "X_train_top = X_train[:, indices]\n",
    "X_test_top = X_test[:, indices]\n",
    "\n",
    "# Train new model on selected features\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_top, y_train)\n",
    "\n",
    "# Predict and save\n",
    "y_pred = model.predict(X_test_top)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": y_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7d0d5-54f9-4f4a-a2d3-6c2bd4d48bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Transform y using QuantileTransformer\n",
    "qt = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "y_train_transformed = qt.fit_transform(y_train.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Train model on transformed target\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train_transformed)\n",
    "\n",
    "# Predict and inverse transform\n",
    "y_pred_transformed = model.predict(X_test)\n",
    "y_pred = qt.inverse_transform(y_pred_transformed.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Save predictions\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": y_pred\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f0fb4e-798f-487a-ad31-649275107265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Train 5 different RandomForest models\n",
    "models = []\n",
    "for seed in [0, 1, 2, 3, 4]:\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=seed, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    models.append(rf)\n",
    "\n",
    "# Predict from each and average\n",
    "predictions = np.mean([model.predict(X_test) for model in models], axis=0)\n",
    "\n",
    "# Save to CSV\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59ecd0-f9c6-4bdb-9bf7-a5e49f295bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def extract_features_single(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # Statistical aggregates\n",
    "        mfcc_mean = np.mean(mfcc, axis=1)\n",
    "        mfcc_std = np.std(mfcc, axis=1)\n",
    "        mfcc_min = np.min(mfcc, axis=1)\n",
    "        mfcc_max = np.max(mfcc, axis=1)\n",
    "        mfcc_median = np.median(mfcc, axis=1)\n",
    "\n",
    "        features = np.hstack([mfcc_mean, mfcc_std, mfcc_min, mfcc_max, mfcc_median])\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c1536-560c-4ae0-98d5-47a4048baf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def build_features(df, audio_dir):\n",
    "    features = []\n",
    "    valid_filenames = []\n",
    "\n",
    "    for fname in tqdm(df['filename'], desc=\"Extracting MFCC\"):\n",
    "        path = os.path.join(audio_dir, fname)\n",
    "        if os.path.exists(path):\n",
    "            feat = extract_features_single(path)\n",
    "            if feat is not None:\n",
    "                features.append(feat)\n",
    "                valid_filenames.append(fname)\n",
    "        else:\n",
    "            print(f\"File not found: {path}\")\n",
    "\n",
    "    return np.array(features), valid_filenames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494fd4d3-e0eb-46c6-8819-40f425e2e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate features with new function\n",
    "X_train, train_valid_files = build_features(train_df, TRAIN_AUDIO_FOLDER)\n",
    "X_test, test_valid_files = build_features(test_df, TEST_AUDIO_FOLDER)\n",
    "\n",
    "# Update your target\n",
    "y_train = train_df.loc[train_df['filename'].isin(train_valid_files), 'label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19d42b-c2d9-42c0-b852-b240affcb37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "best_rf = RandomForestRegressor(n_estimators=300, max_depth=12, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e8794-e905-4a39-a310-9c0293648d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5d649-c2db-4e41-8524-287965da97b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_single(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # Features\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    spec_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    rms = librosa.feature.rms(y=y)\n",
    "    tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "\n",
    "    # Combine\n",
    "    combined = np.vstack([\n",
    "        mfcc, delta, delta2, chroma, zcr,\n",
    "        spec_contrast, spec_centroid,\n",
    "        rms, tonnetz\n",
    "    ])\n",
    "\n",
    "    # Aggregate stats\n",
    "    features = np.concatenate([\n",
    "        np.mean(combined, axis=1),\n",
    "        np.std(combined, axis=1),\n",
    "        np.min(combined, axis=1),\n",
    "        np.max(combined, axis=1),\n",
    "        np.median(combined, axis=1)\n",
    "    ])\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258b865e-586c-442f-8c0a-038aee2afa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting MFCC:  60%|█████████████████████████████████████▉                         | 267/444 [27:49<30:51, 10.46s/it]"
     ]
    }
   ],
   "source": [
    "X_train, train_valid_files = build_features(train_df, TRAIN_AUDIO_FOLDER)\n",
    "y_train = train_df[\"label\"].values\n",
    "\n",
    "X_test, test_valid_files = build_features(test_df, TEST_AUDIO_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08efef40-399c-4c2f-9ae6-002995c70a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "best_rf = RandomForestRegressor(n_estimators=300, max_depth=12, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da46aec-ef09-4b92-8ecc-2351dfdf0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = best_rf.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_valid_files,\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11bb317-b6a5-411c-9519-f7df573ddfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
